# Testing Setup - Quick Start Guide

## Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Run All Tests
```bash
python run_tests.py
```

### 3. Run Specific Test Categories
```bash
# Unit tests only (fastest)
python run_tests.py unit

# FastAPI endpoint tests
python run_tests.py fastapi

# Integration tests
python run_tests.py integration

# Complete end-to-end tests
python run_tests.py complete
```

## Test Files Created

1. **`test_fastapi_endpoints.py`** - Comprehensive FastAPI endpoint tests
   - All HTTP endpoints (/chat, /dryrun, /health, /)
   - Request/response validation
   - Error handling and middleware
   - Template service integration

2. **`test_mocks.py`** - External service mocking tests
   - LLM client mocking (OpenRouter)
   - n8n client mocking  
   - Template service mocking
   - Workflow agent with mocked dependencies

3. **`test_error_scenarios.py`** - Error handling and edge cases
   - Network failures and timeouts
   - Invalid responses and authentication errors
   - Service unavailability scenarios
   - FastAPI error handling

4. **`test_complete_integration.py`** - End-to-end integration tests
   - Complete workflow creation scenarios
   - Multi-service coordination
   - Error recovery and resilience testing
   - System recovery after failures

## Key Features

âœ… **Proper Async/Await Patterns**: All tests use correct asyncio patterns with pytest-asyncio  
âœ… **Comprehensive Mocking**: External services mocked to run without dependencies  
âœ… **Error Scenarios**: Extensive error handling and edge case testing  
âœ… **Integration Testing**: Complete workflow validation from request to n8n creation  
âœ… **Performance Focused**: Tests designed to run efficiently with proper cleanup  

## Test Categories

- **Unit Tests** (`-m unit`): Individual component testing
- **FastAPI Tests** (`-m fastapi`): HTTP endpoint testing  
- **Mock Tests** (`-m mocks`): Service mocking validation
- **Error Tests** (`-m errors`): Error handling and edge cases
- **Integration Tests** (`-m integration`): Component interaction testing
- **Complete Tests** (`-m complete`): End-to-end system testing

## Running Tests

### Using Test Runner (Recommended)
```bash
# All tests with service health checks
python run_tests.py

# Specific categories
python run_tests.py unit
python run_tests.py fastapi  
python run_tests.py mocks
python run_tests.py errors
python run_tests.py integration
python run_tests.py complete

# Check service health only
python run_tests.py check
```

### Using pytest Directly
```bash
# All tests
pytest -v

# By marker
pytest -m unit -v
pytest -m fastapi -v
pytest -m integration -v

# Specific files
pytest test_fastapi_endpoints.py -v
pytest test_complete_integration.py -v

# With coverage
pytest --cov=. --cov-report=html -v
```

## Test Environment

### Required Environment Variables
```bash
# Mock API key for testing (not a real key)
export OPENROUTER_API_KEY="test-key-for-testing"
```

### Optional Service URLs
```bash
export N8N_URL="http://localhost:5678"
export TEMPLATE_SERVICE_URL="http://localhost:8000"  
export AGENT_API_URL="http://localhost:8001"
```

## What Tests Cover

### FastAPI Endpoints
- âœ… `/` root endpoint with API information
- âœ… `/chat` endpoint with workflow creation
- âœ… `/dryrun` endpoint for template search
- âœ… `/health` endpoint with service status
- âœ… Request validation and error handling
- âœ… Middleware (CORS, GZip, logging)

### LLM Client  
- âœ… OpenRouter API integration
- âœ… Intent extraction from user messages
- âœ… Template scoring and ranking
- âœ… Response generation
- âœ… Error handling and retry logic

### n8n Client
- âœ… Workflow creation and management
- âœ… API path detection (/api/v1 vs /rest)
- âœ… Workflow activation and status
- âœ… Connection testing and health checks

### LangGraph Agent
- âœ… Complete workflow state machine
- âœ… Multi-step processing pipeline
- âœ… Template search and selection
- âœ… Conditional routing and decision logic
- âœ… Error recovery and retry mechanisms

### Error Scenarios
- âœ… Network failures and timeouts
- âœ… Invalid API responses
- âœ… Authentication and authorization errors
- âœ… Service unavailability
- âœ… Malformed data handling

### Integration Testing  
- âœ… Complete request-to-workflow flows
- âœ… Multi-service coordination
- âœ… Error recovery and fallback behavior
- âœ… System resilience testing

## Test Results

When you run the tests, you'll see comprehensive output including:

```
ðŸ“‹ Test Execution Plan:
  1. Unit Tests (no external dependencies)
  2. FastAPI Endpoint Tests (with mocking)
  3. Mock Tests (testing mock functionality)
  4. Error Scenario Tests (error handling)  
  5. Integration Tests (with service mocking)
  6. Complete Integration Tests (end-to-end)

ðŸ“Š Test Results Summary:
==========================================
Unit Tests:              âœ… PASSED
FastAPI Endpoint Tests:  âœ… PASSED
Mock Tests:              âœ… PASSED
Error Scenario Tests:    âœ… PASSED
Integration Tests:       âœ… PASSED
Complete Integration:    âœ… PASSED

ðŸŽ‰ All test suites passed!
```

## Troubleshooting

### Common Issues

**Import errors**: Make sure all dependencies are installed
```bash
pip install -r requirements.txt
```

**Async issues**: Tests use pytest-asyncio, ensure it's installed
```bash
pip install pytest-asyncio
```

**Mock issues**: Check that mocks are properly configured in test setup

**Environment issues**: Set required environment variables
```bash
export OPENROUTER_API_KEY="test-key-for-testing"
```

### Getting Detailed Output
```bash
# Verbose output with all details
python run_tests.py unit -v

# Run with pytest directly for more control
pytest test_fastapi_endpoints.py -v -s --tb=long
```

## Next Steps

1. **Run the tests**: `python run_tests.py`
2. **Check coverage**: `pytest --cov=. --cov-report=html`
3. **Review results**: Open `htmlcov/index.html` for coverage report
4. **Add more tests**: Extend existing test files as needed

The test suite is designed to run without requiring external services, using comprehensive mocking to simulate all external dependencies. This ensures tests are fast, reliable, and can run in any environment.